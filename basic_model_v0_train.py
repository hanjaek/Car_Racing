import os
import gymnasium as gym
from stable_baselines3 import SAC
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.monitor import Monitor

# âœ… ëª¨ë¸ ë° ë¡œê·¸ ì €ì¥í•  í´ë” ì„¤ì •
MODEL_DIR = "basic_model_v0"
LOG_DIR = "tensorboard_logs"  
MODEL_PATH = os.path.join(MODEL_DIR, "sac_car_racing_best")

# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
os.makedirs(MODEL_DIR, exist_ok=True)
os.makedirs(LOG_DIR, exist_ok=True)

# âœ… CarRacing í™˜ê²½ ìƒì„±
env = gym.make("CarRacing-v3", domain_randomize=False, render_mode="rgb_array")
env = Monitor(env)
env = DummyVecEnv([lambda: env])

# âœ… ê¸°ì¡´ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° or ìƒˆë¡œìš´ ëª¨ë¸ ìƒì„±
try:
    model = SAC.load(MODEL_PATH, env=env, tensorboard_log=LOG_DIR)
    print(f"âœ… ê¸°ì¡´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ ì¶”ê°€ í•™ìŠµí•©ë‹ˆë‹¤. ({MODEL_PATH})")
except:
    print("ğŸš€ ê¸°ì¡´ ëª¨ë¸ì´ ì—†ì–´ì„œ ìƒˆë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    model = SAC(
        "CnnPolicy",
        env,
        learning_rate=3e-4,
        buffer_size=1000000,
        batch_size=256,
        tau=0.005,
        gamma=0.99,
        train_freq=1,
        gradient_steps=1,
        verbose=1,
        tensorboard_log=LOG_DIR  # âœ… SAC ìë™ ë¡œê·¸ë§Œ ì €ì¥
    )

# âœ… í•™ìŠµ ìˆ˜í–‰ 
model.learn(total_timesteps=3000000)

# âœ… ëª¨ë¸ ì €ì¥
model.save(MODEL_PATH)
print(f"ğŸ’¾ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ëª¨ë¸ì´ '{MODEL_PATH}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
